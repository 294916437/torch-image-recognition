import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import os
import time
import copy
from torch.multiprocessing import freeze_support
import torchvision.models as models
from torch.utils.tensorboard import SummaryWriter

# æŒ‡å®šä½¿ç”¨ GPU 0
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
# å¯ç”¨ cuDNN çš„è‡ªåŠ¨è°ƒæ•´ç®—æ³•ä»¥åŠ é€Ÿå·ç§¯æ“ä½œ
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.deterministic = False  # ä½¿ç”¨éç¡®å®šæ€§ç®—æ³•ä»¥æé«˜æ€§èƒ½
# 1. æ•°æ®å‡†å¤‡å‡½æ•°æ·»åŠ å¼‚å¸¸å¤„ç†
def prepare_data():
    try:
        data_dir = './data/Medicine'

        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        if not os.path.exists(data_dir):
            print(f"æ•°æ®ç›®å½• '{data_dir}' ä¸å­˜åœ¨ã€‚è¯·åˆ›å»ºè¯¥ç›®å½•å¹¶æ”¾å…¥ä¸­åŒ»è¯å›¾åƒæ•°æ®ã€‚")
            exit()

        # æ£€æŸ¥è®­ç»ƒå’Œæµ‹è¯•ç›®å½•
        train_dir = os.path.join(data_dir, 'train')
        test_dir = os.path.join(data_dir, 'test')

        if not os.path.exists(train_dir) or not os.path.exists(test_dir):
            print(f"è®­ç»ƒæˆ–æµ‹è¯•ç›®å½•ä¸å­˜åœ¨ã€‚è¯·ç¡®ä¿åœ¨ '{data_dir}' ä¸‹æœ‰ 'train' å’Œ 'test' æ–‡ä»¶å¤¹ã€‚")
            exit()

        # è·å–ç±»åˆ«åˆ—è¡¨
        classes = sorted([d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))])
        num_classes = len(classes)
        
        # ç®€åŒ–æ•°æ®é¢„å¤„ç†ä»¥åŠ é€Ÿè®­ç»ƒ
        transform_train = transforms.Compose([
            transforms.RandomResizedCrop(224),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        transform_test = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        # ä½¿ç”¨ ImageFolder åŠ è½½æ•°æ®
        trainset = torchvision.datasets.ImageFolder(root=train_dir, transform=transform_train)
        testset = torchvision.datasets.ImageFolder(root=test_dir, transform=transform_test)

        # é™ä½æ‰¹é‡å¤§å°ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
        trainloader = DataLoader(trainset, batch_size=96, shuffle=True, 
                                num_workers=8, pin_memory=True)
        testloader = DataLoader(testset, batch_size=96, shuffle=False, 
                               num_workers=8, pin_memory=True)
        
        return trainloader, testloader, classes, num_classes
    except Exception as e:
        print(f"æ•°æ®å‡†å¤‡é˜¶æ®µå‘ç”Ÿé”™è¯¯: {str(e)}")
        exit(1)

# 2. ä¿®æ”¹è®­ç»ƒå‡½æ•°æ·»åŠ å¼‚å¸¸å¤„ç†
def train_model(model, criterion, optimizer, scheduler, num_epochs=50, patience=10):
    start_time = time.time()
    epoch_times = []  # ç”¨äºè®°å½•æ¯ä¸ªepochçš„æ—¶é—´

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    # æ—©åœæœºåˆ¶
    patience_counter = 0
    best_loss = float('inf')

    # æ‰“å°è®­ç»ƒå¼€å§‹ä¿¡æ¯
    start_time_str = time.strftime("%H:%M:%S")
    print(f"\n=== è®­ç»ƒå¼€å§‹äº {start_time_str} ===")
    print(f"ä½¿ç”¨MobileNetV3 Smallæ¨¡å‹ + æ ‡å‡†è®­ç»ƒ + æ‰¹é‡å¤§å°96")
    print(f"å…± {num_epochs} è½®è®­ç»ƒï¼Œæ¯è½®æœ‰ {len(trainloader)} ä¸ªè®­ç»ƒæ‰¹æ¬¡å’Œ {len(testloader)} ä¸ªéªŒè¯æ‰¹æ¬¡")

    for epoch in range(num_epochs):
        try:
            epoch_start = time.time()
            
            print(f"\n[Epoch {epoch+1}/{num_epochs}]" + "=" * 40)
            
            # æ¯ä¸ª epoch æœ‰è®­ç»ƒå’ŒéªŒè¯é˜¶æ®µ
            for phase in ['train', 'val']:
                try:
                    if phase == 'train':
                        model.train()  # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
                        dataloader = trainloader
                        phase_desc = "è®­ç»ƒé˜¶æ®µ"
                    else:
                        model.eval()   # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
                        dataloader = testloader
                        phase_desc = "éªŒè¯é˜¶æ®µ"

                    print(f"\n[{phase_desc}]")
                    
                    running_loss = 0.0
                    running_corrects = 0
                    batch_count = 0
                    total_batches = len(dataloader)
                    
                    # åœ¨æ¯ä¸ªé˜¶æ®µå¼€å§‹æ—¶æ¸…ç†ç¼“å­˜é‡Šæ”¾å†…å­˜
                    try:
                        if torch.cuda.is_available():
                            torch.cuda.empty_cache()
                    except Exception as e:
                        print(f"æ¸…ç† GPU ç¼“å­˜æ—¶å‡ºé”™: {str(e)}")
                        
                    # è¿­ä»£æ•°æ®
                    for i, (inputs, labels) in enumerate(dataloader):
                        try:
                            batch_start = time.time()
                            inputs = inputs.to(device, non_blocking=True)
                            labels = labels.to(device, non_blocking=True)
                            
                            # æ¢¯åº¦æ¸…é›¶
                            optimizer.zero_grad(set_to_none=True)

                            # å‰å‘ä¼ æ’­ - æ ‡å‡†æ–¹å¼ï¼ˆæ— æ··åˆç²¾åº¦ï¼‰
                            with torch.set_grad_enabled(phase == 'train'):
                                outputs = model(inputs)
                                _, preds = torch.max(outputs, 1)
                                loss = criterion(outputs, labels)

                                # åå‘ä¼ æ’­å’Œä¼˜åŒ– - æ ‡å‡†æ–¹å¼
                                if phase == 'train':
                                    loss.backward()
                                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                                    optimizer.step()
                            
                            # ç»Ÿè®¡
                            batch_size = inputs.size(0)
                            batch_count += 1
                            running_loss += loss.item() * batch_size
                            running_corrects += torch.sum(preds == labels.data).item()
                            
                            # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„æŸå¤±å’Œå‡†ç¡®ç‡
                            try:
                                current_loss = running_loss / (batch_count * batch_size)
                                current_acc = 100 * running_corrects / (batch_count * batch_size)
                            except ZeroDivisionError:
                                print("\nè­¦å‘Š: è®¡ç®—æŸå¤±å’Œå‡†ç¡®ç‡æ—¶å‘ç”Ÿé™¤é›¶é”™è¯¯")
                                current_loss = 0.0
                                current_acc = 0.0
                            
                            # æ¯å¤„ç†ä¸€å®šæ•°é‡çš„æ‰¹æ¬¡æ›´æ–°è¿›åº¦æ¡
                            if i % 10 == 0 or i == total_batches - 1:
                                try:
                                    # è®¡ç®—æ‰¹å¤„ç†é€Ÿåº¦å’Œé¢„ä¼°å‰©ä½™æ—¶é—´
                                    batch_time = time.time() - batch_start
                                    samples_per_sec = batch_size / max(batch_time, 1e-5)  # é¿å…é™¤é›¶
                                    
                                    # æ ¼å¼åŒ–è¾“å‡º
                                    print_str = f"\ræ‰¹æ¬¡: [{i+1}/{total_batches}] "
                                    print_str += f"æŸå¤±: {current_loss:.4f} å‡†ç¡®ç‡: {current_acc:.2f}% "
                                    if i > 0:  # è·³è¿‡ç¬¬ä¸€ä¸ªæ‰¹æ¬¡ï¼Œå› ä¸ºæ—¶é—´å¯èƒ½ä¸å‡†ç¡®
                                        print_str += f"é€Ÿåº¦: {samples_per_sec:.1f}æ ·æœ¬/ç§’"
                                    
                                    print(print_str, end="")
                                except Exception as e:
                                    print(f"\nè­¦å‘Š: æ˜¾ç¤ºè¿›åº¦æ—¶å‡ºé”™: {str(e)}")
                            
                            # åœ¨ TensorBoard ä¸­è®°å½•æ¯ä¸ªæ‰¹æ¬¡çš„æŸå¤± (é™ä½è®°å½•é¢‘ç‡ä»¥æé«˜æ€§èƒ½)
                            try:
                                if phase == 'train' and i % 100 == 0:  # æ¯100ä¸ªæ‰¹æ¬¡è®°å½•ä¸€æ¬¡
                                    batch_idx = epoch * len(dataloader) + i
                                    writer.add_scalar('Batch/loss', loss.item(), batch_idx)
                            except Exception as e:
                                print(f"\nè­¦å‘Š: TensorBoard å†™å…¥æ—¶å‡ºé”™: {str(e)}")
                                
                        except Exception as e:
                            print(f"\nè­¦å‘Š: å¤„ç†æ‰¹æ¬¡ {i+1}/{total_batches} æ—¶å‡ºé”™: {str(e)}")
                            print("ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹æ¬¡...")
                            continue
                            
                        finally:
                            # ä¸»åŠ¨é‡Šæ”¾ä¸éœ€è¦çš„å¼ é‡
                            try:
                                del inputs, labels, outputs, preds
                                if phase == 'train' and 'loss' in locals():
                                    del loss
                            except Exception:
                                pass  # å¿½ç•¥æ¸…ç†é”™è¯¯
                    
                    # å®Œæˆä¸€ä¸ªé˜¶æ®µåæ¢è¡Œå’Œè®¡ç®—æ€»æŒ‡æ ‡
                    print()  # ç¡®ä¿è¿›åº¦æ¡åæ¢è¡Œ
                    
                    try:
                        # è®¡ç®—é˜¶æ®µæ€»ä½“æŒ‡æ ‡
                        dataset_size = len(dataloader.dataset)
                        if dataset_size > 0 and batch_count > 0:
                            epoch_loss = running_loss / dataset_size
                            epoch_acc = running_corrects / dataset_size
                        else:
                            print("è­¦å‘Š: æ•°æ®é›†å¤§å°ä¸º0æˆ–æ‰¹æ¬¡è®¡æ•°ä¸º0")
                            epoch_loss = 0.0
                            epoch_acc = 0.0
                        
                        # æ‰“å°é˜¶æ®µç»“æœ
                        print(f"{phase_desc} å®Œæˆ - æŸå¤±: {epoch_loss:.4f}, å‡†ç¡®ç‡: {epoch_acc:.4f}")

                        # TensorBoard å†™å…¥
                        writer.add_scalar(f'{phase}/loss', epoch_loss, epoch)
                        writer.add_scalar(f'{phase}/accuracy', epoch_acc, epoch)

                        # å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œä¿å­˜æƒé‡
                        if phase == 'val' and epoch_acc > best_acc:
                            best_acc = epoch_acc
                            best_model_wts = copy.deepcopy(model.state_dict())
                            print(f'âœ… æ–°çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.4f}')
                            # ä¿å­˜æœ€ä½³æ¨¡å‹
                            try:
                                model_save_path = f'medicine_best_model.pth'
                                torch.save(model.state_dict(), model_save_path)
                                print(f'ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_save_path}')
                            except Exception as e:
                                print(f"ä¿å­˜æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")

                        # æ—©åœæœºåˆ¶ç›‘æµ‹
                        if phase == 'val':
                            if epoch_loss < best_loss:
                                best_loss = epoch_loss
                                patience_counter = 0
                            else:
                                patience_counter += 1
                                print(f"âš ï¸ è¿ç»­ {patience_counter}/{patience} è½®æœªæ”¹å–„")
                                if patience_counter >= patience:
                                    print("\nğŸ›‘ è§¦å‘æ—©åœæœºåˆ¶")
                                    time_elapsed = time.time() - start_time
                                    print(f'æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.4f}')
                                    model.load_state_dict(best_model_wts)
                                    return model
                    except Exception as e:
                        print(f"è®¡ç®—é˜¶æ®µæŒ‡æ ‡æ—¶å‡ºé”™: {str(e)}")
                        # ç»§ç»­è®­ç»ƒï¼Œä¸ä¸­æ–­
                
                except Exception as e:
                    print(f"å¤„ç†é˜¶æ®µ {phase} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                    print("å°è¯•ç»§ç»­ä¸‹ä¸€ä¸ªé˜¶æ®µ...")
                    continue

            try:
                # è®¡ç®—å¹¶å­˜å‚¨æœ¬è½®epochçš„æ—¶é—´
                epoch_duration = time.time() - epoch_start
                epoch_times.append(epoch_duration)
                
                # å­¦ä¹ ç‡æ›´æ–°
                if scheduler:
                    try:
                        scheduler.step()
                        # è®°å½•å­¦ä¹ ç‡
                        current_lr = scheduler.get_last_lr()
                        writer.add_scalar('Learning_rate', current_lr[0], epoch)
                        print(f"ğŸ“Š å½“å‰å­¦ä¹ ç‡: {current_lr[0]:.6f}")
                    except Exception as e:
                        print(f"æ›´æ–°å­¦ä¹ ç‡æ—¶å‡ºé”™: {str(e)}")
                
                # æ˜¾ç¤ºæœ¬è½®ç”¨æ—¶
                print(f"â±ï¸ æœ¬è½®ç”¨æ—¶: {epoch_duration:.1f}ç§’")
                
                # è¿›åº¦æ€»ç»“
                overall_progress = (epoch + 1) / num_epochs * 100
                print(f"æ€»è¿›åº¦: {overall_progress:.1f}% [{epoch+1}/{num_epochs}]")
            except Exception as e:
                print(f"æ›´æ–°è½®æ€»ç»“æ—¶å‡ºé”™: {str(e)}")
                
        except Exception as e:
            print(f"è½® {epoch+1} è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            print("å°è¯•ç»§ç»­ä¸‹ä¸€è½®è®­ç»ƒ...")
            continue

    try:
        # è®­ç»ƒç»“æŸï¼Œæ˜¾ç¤ºæ€»ç»“ä¿¡æ¯
        time_elapsed = time.time() - start_time
        end_time_str = time.strftime("%H:%M:%S")
        print(f"\n=== è®­ç»ƒç»“æŸäº {end_time_str} ===")
        print(f"æ€»ç”¨æ—¶: {time_elapsed:.1f}ç§’")
        print(f'æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.4f}')
        print("-" * 60)

        # åŠ è½½æœ€ä½³æ¨¡å‹æƒé‡
        model.load_state_dict(best_model_wts)
    except Exception as e:
        print(f"è®­ç»ƒç»“æŸåå¤„ç†æ—¶å‡ºé”™: {str(e)}")
        
    return model

# 3. åœ¨æµ‹è¯•å’Œè¯„ä¼°é˜¶æ®µæ·»åŠ å¼‚å¸¸å¤„ç†
if __name__ == '__main__':
    # å¤šè¿›ç¨‹æ”¯æŒ
    freeze_support()
    
    try:
        # è°ƒç”¨æ•°æ®å‡†å¤‡å‡½æ•°ï¼Œåªæ‰§è¡Œä¸€æ¬¡
        trainloader, testloader, classes, num_classes = prepare_data()
        
        # ä½¿ç”¨ MobileNetV3 Small 
        model = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)
        num_ftrs = model.classifier[3].in_features
        model.classifier[3] = nn.Linear(num_ftrs, num_classes)
        
        # 3. è®­ç»ƒæ¨¡å‹
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        model = model.to(device)
        
        # ä½¿ç”¨æ ‡ç­¾å¹³æ»‘äº¤å‰ç†µæŸå¤±
        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
        
        # ä¼˜åŒ–å™¨ä½¿ç”¨AdamWå¹¶æ·»åŠ æƒé‡è¡°å‡ï¼Œæ ¹æ®æ–°çš„batch sizeè°ƒæ•´å­¦ä¹ ç‡
        optimizer = optim.AdamW([
            {'params': [param for name, param in model.named_parameters() 
                       if 'classifier' not in name], 'lr': 0.0002},
            {'params': model.classifier.parameters(), 'lr': 0.002}
        ], weight_decay=0.01)
        
        # ä½¿ç”¨ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
            optimizer, T_0=10, T_mult=2, eta_min=1e-6
        )
        
        # TensorBoard
        writer = SummaryWriter(f'runs/medicine_classification')
        
        print("å‡†å¤‡è®­ç»ƒæ•°æ®å’Œæ¨¡å‹...")
        
        # è®­ç»ƒæ¨¡å‹ï¼Œé™ä½è½®æ•°åŠ å¿«è®­ç»ƒ
        print("å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        model = train_model(model, criterion, optimizer, scheduler, num_epochs=18, patience=3)
        
        # 5. æ¨¡å‹ä¿å­˜
        try:
            final_model_path = f'medicine_final_model.pth'
            torch.save(model.state_dict(), final_model_path)
            print(f"\nğŸ’¾ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜åˆ°: {final_model_path}")
        except Exception as e:
            print(f"ä¿å­˜æœ€ç»ˆæ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
        
        print("\nå¼€å§‹è¯„ä¼°æ¨¡å‹...")
        # 6. æ¨¡å‹è¯„ä¼° - æ·»åŠ å¼‚å¸¸å¤„ç†
        try:
            correct = 0
            total = 0
            class_correct = list(0. for i in range(num_classes))
            class_total = list(0. for i in range(num_classes))
            
            model.eval()
            with torch.no_grad():  # åªä¿ç•™no_grad
                total_batches = len(testloader)
                print(f"è¯„ä¼°ä¸­... å…± {total_batches} æ‰¹æ¬¡")
                
                for i, data in enumerate(testloader):
                    try:
                        images, labels = data
                        images = images.to(device, non_blocking=True)
                        labels = labels.to(device, non_blocking=True)
                        outputs = model(images)
                        _, predicted = torch.max(outputs.data, 1)
                        total += labels.size(0)
                        correct += (predicted == labels).sum().item()
                        
                        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
                        c = (predicted == labels).squeeze()
                        for j in range(labels.size(0)):
                            try:
                                label = labels[j]
                                class_correct[label] += c[j].item()
                                class_total[label] += 1
                            except Exception as e:
                                print(f"è®¡ç®—ç±»åˆ«å‡†ç¡®ç‡æ—¶å‡ºé”™: {str(e)}")
                        
                        # æ›´æ–°è¿›åº¦æ¡
                        try:
                            progress = (i + 1) / total_batches
                            bar_length = 30
                            filled_length = int(bar_length * progress)
                            bar = 'â–ˆ' * filled_length + 'â–’' * (bar_length - filled_length)
                            current_acc = 100 * correct / total if total > 0 else 0
                            
                            print(f"\rè¯„ä¼°è¿›åº¦: |{bar}| {progress*100:.1f}% - æ‰¹æ¬¡ {i+1}/{total_batches} - å½“å‰å‡†ç¡®ç‡: {current_acc:.2f}%", end="")
                        except Exception as e:
                            print(f"\næ›´æ–°è¿›åº¦æ¡æ—¶å‡ºé”™: {str(e)}")
                        
                    except Exception as e:
                        print(f"\nå¤„ç†è¯„ä¼°æ‰¹æ¬¡ {i+1}/{total_batches} æ—¶å‡ºé”™: {str(e)}")
                        continue
                    finally:
                        # é‡Šæ”¾å†…å­˜
                        try:
                            del images, labels, outputs, predicted
                        except:
                            pass
                
                # å®Œæˆåæ¢è¡Œ
                print()
            
            try:
                # è®¡ç®—æ€»ä½“å‡†ç¡®ç‡
                overall_accuracy = 100 * correct / total if total > 0 else 0
                print(f'\nğŸ¯ æµ‹è¯•é›†ä¸Šçš„æ€»ä½“å‡†ç¡®ç‡: {overall_accuracy:.2f}%')
                
                # æ‰“å°æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
                print('\nğŸ“Š å„ç±»åˆ«å‡†ç¡®ç‡:')
                print('-' * 60)
                print(f"{'ç±»åˆ«':<30} {'å‡†ç¡®ç‡':>10} {'æ ·æœ¬æ•°':>8}")
                print('-' * 60)
                
                # æŒ‰å‡†ç¡®ç‡æ’åºæ˜¾ç¤º
                try:
                    class_accuracies = [(i, 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0) 
                                        for i in range(num_classes)]
                    class_accuracies.sort(key=lambda x: x[1], reverse=True)
                except Exception as e:
                    print(f"æ’åºç±»åˆ«å‡†ç¡®ç‡æ—¶å‡ºé”™: {str(e)}")
                    class_accuracies = [(i, 0) for i in range(num_classes)]
                
                # åªæ˜¾ç¤ºå‰10ä¸ªæœ€ä½³å’Œå10ä¸ªæœ€å·®çš„ç±»åˆ«ï¼Œé¿å…è¾“å‡ºè¿‡å¤š
                try:
                    print("ã€æœ€ä½³10ä¸ªç±»åˆ«ã€‘")
                    for idx, acc in class_accuracies[:10]:
                        if class_total[idx] > 0:
                            print(f"{classes[idx]:<30} {acc:>8.2f}% {class_total[idx]:>8}")
                            # å°†å„ç±»åˆ«å‡†ç¡®ç‡æ·»åŠ åˆ°TensorBoard
                            writer.add_scalar(f'Test_Accuracy/{classes[idx]}', acc, 0)
                    
                    print("\nã€æœ€å·®10ä¸ªç±»åˆ«ã€‘")
                    for idx, acc in class_accuracies[-10:]:
                        if class_total[idx] > 0:
                            print(f"{classes[idx]:<30} {acc:>8.2f}% {class_total[idx]:>8}")
                            writer.add_scalar(f'Test_Accuracy/{classes[idx]}', acc, 0)
                except Exception as e:
                    print(f"æ˜¾ç¤ºç±»åˆ«å‡†ç¡®ç‡æ—¶å‡ºé”™: {str(e)}")
                
                print('-' * 60)
                
                # æ·»åŠ æ€»ä½“å‡†ç¡®ç‡åˆ°TensorBoard
                writer.add_scalar('Test_Accuracy/Overall', overall_accuracy, 0)
                writer.add_text('Test_Results', f'æ€»ä½“å‡†ç¡®ç‡: {overall_accuracy:.2f}%', 0)
            except Exception as e:
                print(f"è®¡ç®—å’Œæ˜¾ç¤ºå‡†ç¡®ç‡ç»Ÿè®¡æ—¶å‡ºé”™: {str(e)}")
        
        except Exception as e:
            print(f"æ¨¡å‹è¯„ä¼°è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        
        finally:
            try:
                writer.close()  # ç¡®ä¿å…³é—­ TensorBoard
            except:
                pass
            
            print(f"\nâœ… è®­ç»ƒå’Œè¯„ä¼°å®Œæˆ!")
    
    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")